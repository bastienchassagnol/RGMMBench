% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mixture.R
\name{emnmix_multivariate}
\alias{emnmix_multivariate}
\alias{em_Rmixmod_multivariate}
\alias{em_EMCluster_multivariate}
\alias{em_bgmm_multivariate}
\alias{em_flexmix_multivariate}
\alias{em_mixtools_multivariate}
\alias{em_mclust_multivariate}
\alias{em_GMKMcharlie_multivariate}
\alias{em_clustvarsel_multivariate}
\alias{em_HDclassif_multivariate}
\alias{em_pgmm_multivariate}
\alias{em_EMMIXmfa_multivariate}
\title{Custom R implementation of the EM algorithm in the multivariate context}
\usage{
emnmix_multivariate(
  x,
  k,
  itmax = 5000,
  epsilon = 10^-12,
  nstart = 10L,
  start = NULL,
  initialisation_algorithm = "kmeans",
  ...
)

em_Rmixmod_multivariate(
  x = x,
  k = 2,
  initialisation_algorithm = "kmeans",
  itmax = 5000,
  epsilon = 10^-12,
  start = NULL,
  ...
)

em_EMCluster_multivariate(
  x = x,
  k = 2,
  initialisation_algorithm = "kmeans",
  itmax = 5000,
  epsilon = 10^-12,
  start = NULL,
  ...
)

em_bgmm_multivariate(
  x = x,
  k = 2,
  itmax = 5000,
  epsilon = 10^-12,
  initialisation_algorithm = "kmeans",
  start = NULL,
  ...
)

em_flexmix_multivariate(
  x = x,
  k = 2,
  itmax = 5000,
  epsilon = 10^-12,
  minprior = 0.05,
  initialisation_algorithm = "kmeans",
  start = NULL,
  ...
)

em_mixtools_multivariate(
  x = x,
  k = 2,
  initialisation_algorithm = "kmeans",
  itmax = 5000,
  epsilon = 10^-12,
  start = NULL,
  ...
)

em_mclust_multivariate(
  x = x,
  k = 2,
  initialisation_algorithm = "kmeans",
  start = NULL,
  itmax = 5000,
  epsilon = 10^-12,
  ...
)

em_GMKMcharlie_multivariate(
  x = x,
  k = 2,
  initialisation_algorithm = "kmeans",
  embedNoise = 1e-06,
  itmax = 5000,
  epsilon = 10^-12,
  start = NULL,
  parallel = FALSE,
  ...
)

em_clustvarsel_multivariate(
  x = x,
  k = 2,
  initialisation_algorithm = "kmeans",
  itmax = 5000,
  epsilon = 10^-12,
  back_steps = 20,
  start = NULL,
  ...
)

em_HDclassif_multivariate(
  x = x,
  k = 2,
  initialisation_algorithm = "kmeans",
  itmax = 5000,
  epsilon = 10^-12,
  start = NULL,
  kmeans.control = list(iter.max = 200L, nstart = 10L, algorithm = "Hartigan-Wong"),
  mc.cores = getOption("mc.cores", parallel::detectCores())
)

em_pgmm_multivariate(
  x = x,
  k = 2,
  initialisation_algorithm = "kmeans",
  itmax = 5000,
  epsilon = 10^-12,
  aic_acc = 0.1,
  start = NULL,
  arguments_HDclassif = list(init = "kmeans", kmeans.control = list(iter.max = 200L,
    nstart = 10L, algorithm = "Hartigan-Wong"), mc.cores = getOption("mc.cores",
    parallel::detectCores()))
)

em_EMMIXmfa_multivariate(
  x = x,
  k = 2,
  initialisation_algorithm = "kmeans",
  conv_measure = "diff",
  itmax = 5000,
  epsilon = 10^-12,
  start = NULL,
  nkmeans = 10L,
  arguments_HDclassif = list(init = "kmeans", kmeans.control = list(iter.max = 200L,
    nstart = 10L, algorithm = "Hartigan-Wong"), mc.cores = getOption("mc.cores",
    parallel::detectCores()))
)
}
\arguments{
\item{x}{the vector of the observations}

\item{k}{the number of components}

\item{itmax}{the maximal number of iterations to reach the threshold}

\item{epsilon}{the criterion threshold considered as the tolerance between two consecutive log-likelihoods}

\item{start}{a list of initial estimates provided by the user, with 3 entries:
\itemize{
\item The proportions \code{p}: \eqn{p} of each component (must be included between 0 and 1, and sum to one overall)
\item The mean matrix \code{mu}: \eqn{\mathrm{\mu}=(\mu_{i,j}) \in \mathbb{R}^{n \times k}}, with each column
giving the mean values of the variables within a given component
\item The 3-dimensional covariance matrix array \code{Sigma}: \eqn{\mathrm{\Sigma}=(\Sigma_{i,j,l}) \in \mathbb{R}^{n \times n \times k}}, with each matrix
\eqn{\Sigma_{..l}, l \in \{ 1, \ldots, k\}} storing the covariance matrix of a given component,
whose diagonal terms correspond to the variance of each variable, and off-terms diagonal elements return the covariance matrix
}}

\item{initialisation_algorithm, nstart}{hyper-parameters, when the user rather uses
one of our implemented initialization algorithms}

\item{...}{additional parameters for the reviewed packages}

\item{minprior}{Minimum prior probability of clusters, components falling below this threshold are removed during the iteration.}

\item{embedNoise}{
A small constant added to the diagonal entries of all covariance matrices. This may prevent covariance matrices collapsing prematurely. A suggested value is 1e-6. Covariance degeneration is detected during Cholesky decomposition, and will lead the trainer to remove the corresponding mixture component. For high-dimensional problem, setting \code{embedNoise} to nonzero may pose the illusion of massive log-likelihood, all because one or more mixture components are so close to singular, which makes the densities around them extremely high.
}

\item{parallel}{only relevant for GMKMCharlie package which has a native parallel implementation (by default, takes half of the available clusters)}
}
\value{
a list of the estimated parameters, ordered by partial ordering
on their respective mean components for identifiability issues
}
\description{
Custom R implementation of the EM algorithm in the multivariate context
}
\seealso{
\code{\link[=emnmix_univariate]{emnmix_univariate()}} for a bench of algorithms able to perform the Em estimation in the
fully unconstrained case, in the univariate dimension
}
\author{
Bastien CHASSAGNOL
}
